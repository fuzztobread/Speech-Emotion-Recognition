{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9dbf5fe-beb5-44db-9022-04c67cf437c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORT THE LIBRARIES\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# librosa is a Python library for analyzing audio and music. It can be used to extract the data from the audio files we will see it later.\n",
    "import librosa\n",
    "import librosa.display\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import IPython.display as ipd\n",
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "738bf120-9b0c-4f77-9b79-6e908e19ba55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing data set\n",
    "\n",
    "ravdess = \"Z:/dev/machine/audio_speech_actors_01-24/\"\n",
    "Crema = \"Z:/dev/machine/cremad/AudioWAV/\"\n",
    "Tess = \"Z:/dev/machine/tess/\"\n",
    "Savee = \"Z:/dev/machine/savee/ALL/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64960922-42af-4b18-9e52-7b9ff02e9b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_emotion = []\n",
    "file_path = []\n",
    "ravdess_directory_list = os.listdir(ravdess)\n",
    "\n",
    "for i in ravdess_directory_list:\n",
    "    # as their are 24 different actors in our previous directory we need to extract files for each actor.\n",
    "    actor = os.listdir(ravdess + i)\n",
    "    for f in actor:\n",
    "        part = f.split('.')[0].split('-')\n",
    "    # third part in each file represents the emotion associated to that file.\n",
    "        file_emotion.append(int(part[2]))\n",
    "        file_path.append(ravdess + i + '/' + f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b54b140-8813-4241-b9de-816305efc629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Emotions                                               Path\n",
      "0  neutral  Z:/dev/machine/audio_speech_actors_01-24/Actor...\n",
      "1  neutral  Z:/dev/machine/audio_speech_actors_01-24/Actor...\n",
      "2  neutral  Z:/dev/machine/audio_speech_actors_01-24/Actor...\n",
      "3  neutral  Z:/dev/machine/audio_speech_actors_01-24/Actor...\n",
      "4  neutral  Z:/dev/machine/audio_speech_actors_01-24/Actor...\n",
      "______________________________________________\n",
      "     Emotions                                               Path\n",
      "1411    angry  Z:/dev/machine/audio_speech_actors_01-24/Actor...\n",
      "1412    angry  Z:/dev/machine/audio_speech_actors_01-24/Actor...\n",
      "1413    angry  Z:/dev/machine/audio_speech_actors_01-24/Actor...\n",
      "1414    angry  Z:/dev/machine/audio_speech_actors_01-24/Actor...\n",
      "1415    angry  Z:/dev/machine/audio_speech_actors_01-24/Actor...\n",
      "_______________________________________________\n",
      "Emotions\n",
      "neutral    288\n",
      "happy      192\n",
      "sad        192\n",
      "angry      192\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# dataframe for emotion of files\n",
    "emotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])\n",
    "# dataframe for path of files.\n",
    "path_df = pd.DataFrame(file_path, columns=['Path'])\n",
    "ravdess_df = pd.concat([emotion_df, path_df], axis=1)\n",
    "# changing integers to actual emotions.\n",
    "ravdess_df.Emotions.replace({1:'neutral', 2:'neutral', 3:'happy', 4:'sad', 5:'angry', 6:'fear', 7:'disgust',\n",
    "                             8:'surprise'},\n",
    "                            inplace=True)\n",
    "\n",
    "selected_emotions = ['neutral', 'sad', 'happy', 'angry']\n",
    "selected_ravdess_df = ravdess_df[ravdess_df['Emotions'].isin(selected_emotions)]\n",
    "\n",
    "\n",
    "print(selected_ravdess_df.head())\n",
    "print(\"______________________________________________\")\n",
    "print(selected_ravdess_df.tail())\n",
    "print(\"_______________________________________________\")\n",
    "print(selected_ravdess_df.Emotions.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "922664f6-8588-4685-84d1-ac1b90c3b021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotions\n",
      "angry      1271\n",
      "happy      1271\n",
      "sad        1271\n",
      "neutral    1087\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "crema_directory_list = os.listdir(Crema)\n",
    "\n",
    "file_emotion = []\n",
    "file_path = []\n",
    "\n",
    "for file in crema_directory_list:\n",
    "    # storing file paths\n",
    "    file_path.append(Crema + file)\n",
    "    # storing file emotions\n",
    "    part=file.split('_')\n",
    "    if part[2] == 'SAD':\n",
    "        file_emotion.append('sad')\n",
    "    elif part[2] == 'ANG':\n",
    "        file_emotion.append('angry')\n",
    "    elif part[2] == 'DIS':\n",
    "        file_emotion.append('disgust')\n",
    "    elif part[2] == 'FEA':\n",
    "        file_emotion.append('fear')\n",
    "    elif part[2] == 'HAP':\n",
    "        file_emotion.append('happy')\n",
    "    elif part[2] == 'NEU':\n",
    "        file_emotion.append('neutral')\n",
    "    else:\n",
    "        file_emotion.append('Unknown')\n",
    "        \n",
    "# dataframe for emotion of files\n",
    "emotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])\n",
    "\n",
    "# dataframe for path of files.\n",
    "path_df = pd.DataFrame(file_path, columns=['Path'])\n",
    "Crema_df = pd.concat([emotion_df, path_df], axis=1)\n",
    "selected_emotions = ['neutral', 'sad', 'happy', 'angry']\n",
    "selected_crema_df = Crema_df[Crema_df['Emotions'].isin(selected_emotions)]\n",
    "selected_crema_df.head()\n",
    "print(selected_crema_df.Emotions.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22a13422-ffa3-4905-8c30-c31a53563995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotions\n",
      "angry      400\n",
      "happy      400\n",
      "neutral    400\n",
      "sad        400\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "tess_directory_list = os.listdir(Tess)\n",
    "\n",
    "file_emotion = []\n",
    "file_path = []\n",
    "\n",
    "for dir in tess_directory_list:\n",
    "    directories = os.listdir(Tess + dir)\n",
    "    for file in directories:\n",
    "        part = file.split('.')[0]\n",
    "        part = part.split('_')[2]\n",
    "        if part=='ps':\n",
    "            file_emotion.append('surprise')\n",
    "        else:\n",
    "            file_emotion.append(part)\n",
    "        file_path.append(Tess + dir + '/' + file)\n",
    "        \n",
    "# dataframe for emotion of files\n",
    "emotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])\n",
    "\n",
    "# dataframe for path of files.\n",
    "path_df = pd.DataFrame(file_path, columns=['Path'])\n",
    "\n",
    "Tess_df = pd.concat([emotion_df, path_df], axis=1)\n",
    "\n",
    "selected_emotions = ['neutral', 'sad', 'happy', 'angry']\n",
    "selected_tess_df = Tess_df[Tess_df['Emotions'].isin(selected_emotions)]\n",
    "\n",
    "selected_tess_df.head()\n",
    "print(selected_tess_df.Emotions.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4d2b68f-bf16-43fe-9e2c-d53fce539a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotions\n",
      "angry      400\n",
      "happy      400\n",
      "neutral    400\n",
      "sad        400\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "savee_directory_list = os.listdir(Savee)\n",
    "\n",
    "file_emotion = []\n",
    "file_path = []\n",
    "\n",
    "for file in savee_directory_list:\n",
    "    file_path.append(Savee + file)\n",
    "    part = file.split('_')[1]\n",
    "    ele = part[:-6]\n",
    "    if ele=='a':\n",
    "        file_emotion.append('angry')\n",
    "    elif ele=='d':\n",
    "        file_emotion.append('disgust')\n",
    "    elif ele=='f':\n",
    "        file_emotion.append('fear')\n",
    "    elif ele=='h':\n",
    "        file_emotion.append('happy')\n",
    "    elif ele=='n':\n",
    "        file_emotion.append('neutral')\n",
    "    elif ele=='sa':\n",
    "        file_emotion.append('sad')\n",
    "    else:\n",
    "        file_emotion.append('surprise')\n",
    "        \n",
    "# dataframe for emotion of files\n",
    "emotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])\n",
    "\n",
    "# dataframe for path of files.\n",
    "path_df = pd.DataFrame(file_path, columns=['Path'])\n",
    "Savee_df = pd.concat([emotion_df, path_df], axis=1)\n",
    "selected_emotions = ['neutral', 'sad', 'happy', 'angry']\n",
    "selected_save_df = Tess_df[Tess_df['Emotions'].isin(selected_emotions)]\n",
    "\n",
    "selected_save_df.head()\n",
    "print(selected_save_df.Emotions.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "550ee8bb-359b-421c-8118-5ccbbf9ba350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotions</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Z:/dev/machine/audio_speech_actors_01-24/Actor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Z:/dev/machine/audio_speech_actors_01-24/Actor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Z:/dev/machine/audio_speech_actors_01-24/Actor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Z:/dev/machine/audio_speech_actors_01-24/Actor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Z:/dev/machine/audio_speech_actors_01-24/Actor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Emotions                                               Path\n",
       "0  neutral  Z:/dev/machine/audio_speech_actors_01-24/Actor...\n",
       "1  neutral  Z:/dev/machine/audio_speech_actors_01-24/Actor...\n",
       "2  neutral  Z:/dev/machine/audio_speech_actors_01-24/Actor...\n",
       "3  neutral  Z:/dev/machine/audio_speech_actors_01-24/Actor...\n",
       "4  neutral  Z:/dev/machine/audio_speech_actors_01-24/Actor..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = pd.concat([selected_ravdess_df, selected_tess_df, selected_save_df, selected_crema_df], axis = 0)\n",
    "data_path.to_csv(\"data_path.csv\",index=False)\n",
    "data_path.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "35a5ccf3-d283-44b9-a5d1-50aed8be8d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise(data):\n",
    "    noise_amp = 0.035*np.random.uniform()*np.amax(data)\n",
    "    data = data + noise_amp*np.random.normal(size=data.shape[0])\n",
    "    return data\n",
    "\n",
    "def stretch(data, rate=0.8):\n",
    "    return librosa.effects.time_stretch(data, rate=rate)\n",
    "\n",
    "def shift(data):\n",
    "    shift_range = int(np.random.uniform(low=-5, high = 5)*1000)\n",
    "    return np.roll(data, shift_range)\n",
    "\n",
    "def pitch(data, sampling_rate, pitch_factor=0.7):\n",
    "    return librosa.effects.pitch_shift(data, sr=sampling_rate, n_steps=pitch_factor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d867f66f-5250-46c0-a111-75e53b295c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(data):\n",
    "    # ZCR\n",
    "    result = np.array([])\n",
    "    zcr = np.mean(librosa.feature.zero_crossing_rate(y=data).T, axis=0)\n",
    "    result=np.hstack((result, zcr)) # stacking horizontally\n",
    "\n",
    "    # Chroma_stft\n",
    "    stft = np.abs(librosa.stft(data))\n",
    "    chroma_stft = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T, axis=0)\n",
    "    result = np.hstack((result, chroma_stft)) # stacking horizontally\n",
    "\n",
    "    # MFCC\n",
    "    mfcc = np.mean(librosa.feature.mfcc(y=data, sr=sample_rate).T, axis=0)\n",
    "    result = np.hstack((result, mfcc)) # stacking horizontally\n",
    "\n",
    "    # Root Mean Square Value\n",
    "    rms = np.mean(librosa.feature.rms(y=data).T, axis=0)\n",
    "    result = np.hstack((result, rms)) # stacking horizontally\n",
    "\n",
    "    # MelSpectogram\n",
    "    mel = np.mean(librosa.feature.melspectrogram(y=data, sr=sample_rate).T, axis=0)\n",
    "    result = np.hstack((result, mel)) # stacking horizontally\n",
    "    \n",
    "    return result\n",
    "\n",
    "def get_features(path):\n",
    "    # duration and offset are used to take care of the no audio in start and the ending of each audio files as seen above.\n",
    "    data, sample_rate = librosa.load(path, duration=2.5, offset=0.6)\n",
    "    \n",
    "    # without augmentation\n",
    "    res1 = extract_features(data)\n",
    "    result = np.array(res1)\n",
    "    \n",
    "    # data with noise\n",
    "    noise_data = noise(data)\n",
    "    res2 = extract_features(noise_data)\n",
    "    result = np.vstack((result, res2)) # stacking vertically\n",
    "    \n",
    "    # data with stretching and pitching\n",
    "    new_data = stretch(data)\n",
    "    data_stretch_pitch = pitch(new_data, sample_rate)\n",
    "    res3 = extract_features(data_stretch_pitch)\n",
    "    result = np.vstack((result, res3)) # stacking vertically\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e670e94c-71e7-45db-a3ef-5987d9986e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00,  7.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 audio has been processed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "502it [01:08,  7.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 audio has been processed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1002it [02:08, 13.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 audio has been processed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1502it [02:51,  9.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500 audio has been processed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2002it [03:39, 12.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 audio has been processed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2504it [04:25, 15.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500 audio has been processed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3002it [05:03, 11.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000 audio has been processed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3502it [05:49, 12.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3500 audio has been processed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4002it [06:32, 10.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000 audio has been processed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4502it [07:31,  8.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4500 audio has been processed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5002it [08:25, 10.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 audio has been processed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5502it [09:18,  8.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5500 audio has been processed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6002it [10:12,  9.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000 audio has been processed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6502it [11:06, 10.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6500 audio has been processed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7002it [11:58,  9.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000 audio has been processed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7502it [12:52,  7.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500 audio has been processed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8002it [13:45, 10.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000 audio has been processed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8137it [14:01,  9.40it/s]C:\\Users\\abina\\miniconda3\\envs\\test\\lib\\site-packages\\librosa\\core\\pitch.py:101: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  return pitch_tuning(\n",
      "8501it [14:40,  8.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8500 audio has been processed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8964it [15:31,  9.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Time:  931.640261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "from tqdm import tqdm\n",
    "start = timeit.default_timer()\n",
    "X,Y=[],[]\n",
    "for path,emotion,index in tqdm (zip(data_path.Path,data_path.Emotions,range(data_path.Path.shape[0]))):\n",
    "    features=get_features(path)\n",
    "    if index%500==0:\n",
    "        print(f'{index} audio has been processed')\n",
    "    for i in features:\n",
    "        X.append(i)\n",
    "        Y.append(emotion)\n",
    "print('Done')\n",
    "stop = timeit.default_timer()\n",
    "\n",
    "print('Time: ', stop - start)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aafc545e-deeb-4d91-9fb0-0373e1ce5c50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26892, 26892, (8964,))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X), len(Y), data_path.Path.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ecb8522e-48b1-40e1-9f67-154d53e24ef1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>153</th>\n",
       "      <th>154</th>\n",
       "      <th>155</th>\n",
       "      <th>156</th>\n",
       "      <th>157</th>\n",
       "      <th>158</th>\n",
       "      <th>159</th>\n",
       "      <th>160</th>\n",
       "      <th>161</th>\n",
       "      <th>Emotions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.321275</td>\n",
       "      <td>0.729664</td>\n",
       "      <td>0.750033</td>\n",
       "      <td>0.730624</td>\n",
       "      <td>0.735275</td>\n",
       "      <td>0.713529</td>\n",
       "      <td>0.660531</td>\n",
       "      <td>0.684966</td>\n",
       "      <td>0.733049</td>\n",
       "      <td>0.753972</td>\n",
       "      <td>...</td>\n",
       "      <td>4.310903e-06</td>\n",
       "      <td>3.291511e-06</td>\n",
       "      <td>2.148075e-06</td>\n",
       "      <td>2.279739e-06</td>\n",
       "      <td>5.116492e-06</td>\n",
       "      <td>8.190282e-06</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>4.245834e-07</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.316031</td>\n",
       "      <td>0.810181</td>\n",
       "      <td>0.809943</td>\n",
       "      <td>0.803690</td>\n",
       "      <td>0.820234</td>\n",
       "      <td>0.797460</td>\n",
       "      <td>0.684320</td>\n",
       "      <td>0.696940</td>\n",
       "      <td>0.741394</td>\n",
       "      <td>0.774245</td>\n",
       "      <td>...</td>\n",
       "      <td>4.915551e-05</td>\n",
       "      <td>4.840747e-05</td>\n",
       "      <td>5.131785e-05</td>\n",
       "      <td>5.286839e-05</td>\n",
       "      <td>5.278305e-05</td>\n",
       "      <td>5.427450e-05</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>4.987747e-05</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.188227</td>\n",
       "      <td>0.622132</td>\n",
       "      <td>0.699217</td>\n",
       "      <td>0.753340</td>\n",
       "      <td>0.721217</td>\n",
       "      <td>0.701731</td>\n",
       "      <td>0.682358</td>\n",
       "      <td>0.662839</td>\n",
       "      <td>0.686496</td>\n",
       "      <td>0.733970</td>\n",
       "      <td>...</td>\n",
       "      <td>8.579046e-07</td>\n",
       "      <td>9.576654e-07</td>\n",
       "      <td>7.733597e-07</td>\n",
       "      <td>5.233100e-07</td>\n",
       "      <td>3.593209e-07</td>\n",
       "      <td>9.263777e-07</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>7.753991e-08</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.293566</td>\n",
       "      <td>0.673896</td>\n",
       "      <td>0.722096</td>\n",
       "      <td>0.723508</td>\n",
       "      <td>0.682302</td>\n",
       "      <td>0.680533</td>\n",
       "      <td>0.675352</td>\n",
       "      <td>0.628977</td>\n",
       "      <td>0.679179</td>\n",
       "      <td>0.707283</td>\n",
       "      <td>...</td>\n",
       "      <td>6.984504e-06</td>\n",
       "      <td>7.034949e-06</td>\n",
       "      <td>6.654922e-06</td>\n",
       "      <td>6.979548e-06</td>\n",
       "      <td>1.214236e-05</td>\n",
       "      <td>9.640185e-06</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>4.254087e-07</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.299176</td>\n",
       "      <td>0.766928</td>\n",
       "      <td>0.798759</td>\n",
       "      <td>0.779664</td>\n",
       "      <td>0.770594</td>\n",
       "      <td>0.778229</td>\n",
       "      <td>0.684694</td>\n",
       "      <td>0.640049</td>\n",
       "      <td>0.698336</td>\n",
       "      <td>0.746909</td>\n",
       "      <td>...</td>\n",
       "      <td>2.902367e-05</td>\n",
       "      <td>2.998370e-05</td>\n",
       "      <td>3.224235e-05</td>\n",
       "      <td>3.128442e-05</td>\n",
       "      <td>3.616239e-05</td>\n",
       "      <td>3.367691e-05</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>2.526569e-05</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 163 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.321275  0.729664  0.750033  0.730624  0.735275  0.713529  0.660531   \n",
       "1  0.316031  0.810181  0.809943  0.803690  0.820234  0.797460  0.684320   \n",
       "2  0.188227  0.622132  0.699217  0.753340  0.721217  0.701731  0.682358   \n",
       "3  0.293566  0.673896  0.722096  0.723508  0.682302  0.680533  0.675352   \n",
       "4  0.299176  0.766928  0.798759  0.779664  0.770594  0.778229  0.684694   \n",
       "\n",
       "          7         8         9  ...           153           154  \\\n",
       "0  0.684966  0.733049  0.753972  ...  4.310903e-06  3.291511e-06   \n",
       "1  0.696940  0.741394  0.774245  ...  4.915551e-05  4.840747e-05   \n",
       "2  0.662839  0.686496  0.733970  ...  8.579046e-07  9.576654e-07   \n",
       "3  0.628977  0.679179  0.707283  ...  6.984504e-06  7.034949e-06   \n",
       "4  0.640049  0.698336  0.746909  ...  2.902367e-05  2.998370e-05   \n",
       "\n",
       "            155           156           157           158       159       160  \\\n",
       "0  2.148075e-06  2.279739e-06  5.116492e-06  8.190282e-06  0.000007  0.000005   \n",
       "1  5.131785e-05  5.286839e-05  5.278305e-05  5.427450e-05  0.000056  0.000056   \n",
       "2  7.733597e-07  5.233100e-07  3.593209e-07  9.263777e-07  0.000002  0.000001   \n",
       "3  6.654922e-06  6.979548e-06  1.214236e-05  9.640185e-06  0.000011  0.000006   \n",
       "4  3.224235e-05  3.128442e-05  3.616239e-05  3.367691e-05  0.000036  0.000030   \n",
       "\n",
       "            161  Emotions  \n",
       "0  4.245834e-07   neutral  \n",
       "1  4.987747e-05   neutral  \n",
       "2  7.753991e-08   neutral  \n",
       "3  4.254087e-07   neutral  \n",
       "4  2.526569e-05   neutral  \n",
       "\n",
       "[5 rows x 163 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Emotions = pd.DataFrame(X)\n",
    "Emotions['Emotions'] = Y\n",
    "Emotions.to_csv('emotion.csv', index=False)\n",
    "Emotions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4503e7d-56ea-43b1-9dbe-167ea3bb9b39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
